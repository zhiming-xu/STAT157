{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Homework 8 - Berkeley STAT 157\n",
    "\n",
    "**Your name: XX, SID YY, teammates A,B,C** (Please add your name, SID and teammates to ease Ryan and Rachel to grade.)\n",
    "\n",
    "**Please submit your homework through [gradescope](http://gradescope.com/)**\n",
    "\n",
    "Handout 4/9/2019, due 4/16/2019 by 4pm.\n",
    "\n",
    "This homework deals with sequence models for text and numbers. Due to the computational cost, we strongly encourage you to implement this on a GPU enabled machine. To make things a bit more interesting we will use a larger text collection here - [Shakespeare's collected works](http://www.gutenberg.org/files/100/100-0.txt) which are freely downloadable at Project Gutenberg. \n",
    "\n",
    "**This is teamwork.**\n",
    "\n",
    "## Prerequisites - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters:  5032359\n",
      "project gutenberg s the complete works of william shakespeare by willi\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import collections\n",
    "import re\n",
    "shakespeare = 'http://www.gutenberg.org/files/100/100-0.txt'\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "text = http.request('GET', shakespeare).data.decode('utf-8')\n",
    "raw_dataset = ' '.join(re.sub('[^A-Za-z]+', ' ', text).lower().split())\n",
    "\n",
    "print('number of characters: ', len(raw_dataset))\n",
    "print(raw_dataset[0:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is quite a bit bigger than the time machine (5 million vs. 160k). For convenience we also include the remaining preprocessing steps. A bigger dataset will allow us to generate more meaningful models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars: project gutenberg s \n",
      "indices: [22, 19, 21, 16, 14, 18, 9, 13, 7, 0, 9, 14, 26, 5, 14, 19, 7, 13, 1, 13]\n"
     ]
    }
   ],
   "source": [
    "idx_to_char = list(set(raw_dataset))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "# vocabulary size, i.e., the number of letters in English\n",
    "vocab_size = len(char_to_idx)\n",
    "# whole corpus\n",
    "corpus_indices = [char_to_idx[char] for char in raw_dataset]\n",
    "sample = corpus_indices[:20]\n",
    "print('chars:', ''.join([idx_to_char[idx] for idx in sample]))\n",
    "print('indices:', sample)\n",
    "# for training\n",
    "train_indices = corpus_indices[:-100000]\n",
    "# for testing\n",
    "test_indices = corpus_indices[-100000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we import other useful libraries to help you getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "import math\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn, rnn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train Recurrent Latent Variable Models\n",
    "\n",
    "Train a number of different latent variable models using `train_indices` to assess their performance. By default pick 256 dimensions for the hidden units. You can use the codes provided in the class. Also, we strongly encourage you to use the Gluon implementation since it's a lot faster than building it from scratch.\n",
    "\n",
    "1. Train a single-layer RNN (with latent variables). \n",
    "1. Train a single-layer GRU.\n",
    "1. Train a single-layer LSTM. \n",
    "1. Train a two-layer LSTM. \n",
    "\n",
    "How low can you drive the perplexity? Can you reproduce some of Shakespeare's finest writing (generate 200 characters). Start the sequence generator with `But Brutus is an honorable man`. Experiment with a number of settings:\n",
    "\n",
    "* Number of hidden units. \n",
    "* Embedding length.\n",
    "* Gradient clipping.\n",
    "* Number of iterations. \n",
    "* Learning rate.\n",
    "\n",
    "**Save** the models (at least in memory since you'll need them in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_gluon(prefix, num_chars, model, vocab_size, ctx, idx_to_char, char_to_idx):\n",
    "    state = model.begin_state(batch_size=1, ctx=ctx)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = nd.array([output[-1]], ctx=ctx).reshape((1, 1))\n",
    "        (Y, state) = model(X, state)\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(axis=1).asscalar()))\n",
    "    return ''.join([idx_to_char[i] for i in output])\n",
    "\n",
    "num_hiddens = 256\n",
    "rnn_layer = rnn.RNN(num_hiddens)\n",
    "rnn_layer.initialize()\n",
    "num_steps = 35\n",
    "num_epochs, batch_size, lr, clipping_theta = 200, 32, 30, 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = d2l.try_gpu()\n",
    "single_rnn_model = d2l.RNNModel(rnn_layer, vocab_size)\n",
    "single_rnn_model.initialize(force_reinit=True, ctx = ctx)\n",
    "pred_period, pred_len, prefixes = 25, 100, ['but brutus is an honorable man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, perplexity 3.698738, time 19.11 sec\n",
      " - but brutus is an honorable man s sooth the state the state the state the state the state the state the state the state the state t\n",
      "epoch 50, perplexity 3.644675, time 18.97 sec\n",
      " - but brutus is an honorable man s son and the state and the state and the state and the state and the state and the state and the s\n",
      "epoch 75, perplexity 3.621387, time 18.90 sec\n",
      " - but brutus is an honorable man s soul that i shall be the state the state the state the state the state the state the state the st\n",
      "epoch 100, perplexity 3.606846, time 18.64 sec\n",
      " - but brutus is an honorable man and the service and the service and the service and the service and the service and the service and\n",
      "epoch 125, perplexity 3.597160, time 18.68 sec\n",
      " - but brutus is an honorable man s soul and the state they shall be the state they shall be the state they shall be the state they s\n",
      "epoch 150, perplexity 3.590280, time 19.11 sec\n",
      " - but brutus is an honorable man s soul and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the \n",
      "epoch 175, perplexity 3.584725, time 18.54 sec\n",
      " - but brutus is an honorable man s soul and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the \n",
      "epoch 200, perplexity 3.580413, time 18.83 sec\n",
      " - but brutus is an honorable man s son and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the s\n"
     ]
    }
   ],
   "source": [
    "# for question 1.1: train a single-layer RNN\n",
    "d2l.train_and_predict_rnn_gluon(single_rnn_model, num_hiddens, vocab_size, ctx, train_indices, idx_to_char,\\\n",
    "                                char_to_idx, num_epochs, num_steps, lr, clipping_theta, batch_size,\\\n",
    "                                pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but brutus is an honorable man s son and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea a'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn_gluon('but brutus is an honorable man', 200, single_rnn_model, vocab_size, ctx,\\\n",
    "                  idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, perplexity 3.382777, time 20.38 sec\n",
      " - but brutus is an honorable man that i will see thee they are they are they are they are they are they are they are they are they a\n",
      "epoch 50, perplexity 3.251212, time 20.35 sec\n",
      " - but brutus is an honorable man that i may be so soon as they are they are they are they are they are they are they are they are th\n",
      "epoch 75, perplexity 3.200615, time 20.43 sec\n",
      " - but brutus is an honorable man that i may say they are a man that i may say they are a man that i may say they are a man that i ma\n",
      "epoch 100, perplexity 3.174369, time 20.29 sec\n",
      " - but brutus is an honorable man that i may see thee when they shall be so soon as they are they are they are they are they are they\n",
      "epoch 125, perplexity 3.156930, time 20.20 sec\n",
      " - but brutus is an honorable man that s a soul of the state of the state of the country s son the sea will be the sea and the consta\n",
      "epoch 150, perplexity 3.145716, time 20.13 sec\n",
      " - but brutus is an honorable man and there is no such a state of the state of the state of the country s son the sea with his soul t\n",
      "epoch 175, perplexity 3.136352, time 20.24 sec\n",
      " - but brutus is an honorable man of man the state of the country s son the sea and the consequence and the stars of the state of the\n",
      "epoch 200, perplexity 3.131308, time 20.36 sec\n",
      " - but brutus is an honorable man of the state of the counterfeit of the state and they are not the state of the counterfeit of the s\n"
     ]
    }
   ],
   "source": [
    "# for question 1.2, single layer lstm\n",
    "lstm_layer = rnn.LSTM(num_hiddens)\n",
    "single_lstm_model = d2l.RNNModel(lstm_layer, vocab_size)\n",
    "d2l.train_and_predict_rnn_gluon(single_lstm_model, num_hiddens, vocab_size, ctx, train_indices, idx_to_char,\\\n",
    "                                char_to_idx, num_epochs, num_steps, lr, clipping_theta, batch_size,\\\n",
    "                                pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but brutus is an honorable man of the state of the counterfeit of the state and they are not the state of the counterfeit of the state and they are not the state of the counterfeit of the state and they are not the state of the co'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn_gluon('but brutus is an honorable man', 200, single_lstm_model, vocab_size, ctx,\\\n",
    "                  idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, perplexity 3.432897, time 20.51 sec\n",
      " - but brutus is an honorable man s son and they are and they are and they are and they are and they are and they are and they are an\n",
      "epoch 50, perplexity 3.347386, time 19.99 sec\n",
      " - but brutus is an honorable man s face they are they shall be so for the sea and the sea and the count s another they are not the s\n",
      "epoch 75, perplexity 3.318542, time 20.20 sec\n",
      " - but brutus is an honorable man that i am a man and they are they are they are they are they are they are they are they are they ar\n",
      "epoch 100, perplexity 3.303343, time 20.56 sec\n",
      " - but brutus is an honorable man s son and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the s\n",
      "epoch 125, perplexity 3.296494, time 19.88 sec\n",
      " - but brutus is an honorable man s son the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea a\n",
      "epoch 150, perplexity 3.289302, time 19.99 sec\n",
      " - but brutus is an honorable man that i will stand for thee they are and there s a fool and there s a fool and there s a fool and th\n",
      "epoch 175, perplexity 3.283573, time 20.18 sec\n",
      " - but brutus is an honorable man that is the sun s and they are so much they say the stage and then they say the stage and then they\n",
      "epoch 200, perplexity 3.279063, time 19.81 sec\n",
      " - but brutus is an honorable man s and the sea and the country s son and then they say the stage and there s a present and so i will\n"
     ]
    }
   ],
   "source": [
    "# for question 1.3, single layer gru\n",
    "gru_layer = rnn.GRU(num_hiddens)\n",
    "single_gru_model = d2l.RNNModel(gru_layer, vocab_size)\n",
    "d2l.train_and_predict_rnn_gluon(single_gru_model, num_hiddens, vocab_size, ctx, train_indices, idx_to_char,\\\n",
    "                                char_to_idx, num_epochs, num_steps, lr, clipping_theta, batch_size,\\\n",
    "                                pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but brutus is an honorable man s and the sea and the country s son and then they say the stage and there s a present and so i will not see thee when i shall see thee when i shall see thee when i shall see thee when i shall see the'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn_gluon('but brutus is an honorable man', 200, single_gru_model, vocab_size, ctx,\\\n",
    "                  idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, perplexity 3.214155, time 30.25 sec\n",
      " - but brutus is an honorable man that s a foot of the country s head and then they say they say they say they say they say they say \n",
      "epoch 50, perplexity 3.007819, time 30.38 sec\n",
      " - but brutus is an honorable man that would be so shall i say the countess is the sea and the senate have and they are they are they\n",
      "epoch 75, perplexity 2.915687, time 30.43 sec\n",
      " - but brutus is an honorable man the thing is the fairest enter servant to the castle enter sir toby and sir toby and sir toby and s\n",
      "epoch 100, perplexity 2.861589, time 30.57 sec\n",
      " - but brutus is an honorable man the third time the sea what s the matter from the capitol the commons have their shame that they wo\n",
      "epoch 125, perplexity 2.824575, time 30.29 sec\n",
      " - but brutus is an honorable mantle s brother s life the first the best and so shall be the most unsure they would not have the sena\n",
      "epoch 150, perplexity 2.799474, time 30.15 sec\n",
      " - but brutus is an honorable man that s the song the fight of heaven and the son of my soul the streets of engling hands and their t\n",
      "epoch 175, perplexity 2.780415, time 30.20 sec\n",
      " - but brutus is an honorable man may well be so betime as i am a soldier that i have seen the day will be the search d head of the c\n",
      "epoch 200, perplexity 2.764609, time 31.21 sec\n",
      " - but brutus is an honorable man s house enter provost and so please you sir toby what she says she did and then to see the stars of\n"
     ]
    }
   ],
   "source": [
    "# for question 1.4, double layers lstm\n",
    "lstm_layer = rnn.LSTM(num_hiddens, num_layers=2)\n",
    "double_lstm_model = d2l.RNNModel(lstm_layer, vocab_size)\n",
    "d2l.train_and_predict_rnn_gluon(double_lstm_model, num_hiddens, vocab_size, ctx, train_indices, idx_to_char,\\\n",
    "                                char_to_idx, num_epochs, num_steps, lr, clipping_theta, batch_size,\\\n",
    "                                pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but brutus is an honorable man s house enter provost and so please you sir toby what she says she did and then to see the stars of men the sea who should say they were not a stranger to the senate house s palace stephano i say sir'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn_gluon('but brutus is an honorable man', 200, double_lstm_model, vocab_size, ctx,\\\n",
    "                  idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "collapsed": true
   },
   "source": [
    "## 2. Test Error\n",
    "\n",
    "So far we measured perplexity only on the training set. \n",
    "\n",
    "1. Implement a perplexity calculator that does not involve training.\n",
    "1. Compute the perplexity of the best models in each of the 4 categories on the test set. By how much does it differ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for question 2\n",
    "# This function is used to test perplexity on test set, not including training\n",
    "def test_perplexity(model, ctx, corpus_indices, idx_to_char, char_to_idx, num_epochs, num_steps, batch_size):\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = d2l.data_iter_consecutive(\n",
    "            corpus_indices, batch_size, num_steps, ctx)\n",
    "        state = model.begin_state(batch_size=batch_size, ctx=ctx)\n",
    "        for X, Y in data_iter:\n",
    "            for s in state:\n",
    "                s.detach()\n",
    "            with autograd.record():\n",
    "                (output, state) = model(X, state)\n",
    "                y = Y.T.reshape((-1,))\n",
    "                l = loss(output, y).mean()\n",
    "            l_sum += l.asscalar() * y.size\n",
    "            n += y.size\n",
    "        print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "            epoch + 1, math.exp(l_sum / n), time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, num_steps, batch_size = 5, 50, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, perplexity 4.705128, time 3.91 sec\n",
      "epoch 2, perplexity 4.706620, time 3.42 sec\n",
      "epoch 3, perplexity 4.704766, time 3.39 sec\n",
      "epoch 4, perplexity 4.704266, time 3.37 sec\n",
      "epoch 5, perplexity 4.704968, time 3.38 sec\n"
     ]
    }
   ],
   "source": [
    "# test perplexity single rnn\n",
    "test_perplexity(single_rnn_model, ctx, test_indices, idx_to_char, char_to_idx, num_epochs, num_steps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, perplexity 4.527095, time 3.33 sec\n",
      "epoch 2, perplexity 4.526816, time 3.42 sec\n",
      "epoch 3, perplexity 4.527897, time 3.64 sec\n",
      "epoch 4, perplexity 4.525007, time 3.63 sec\n",
      "epoch 5, perplexity 4.524860, time 3.47 sec\n"
     ]
    }
   ],
   "source": [
    "# test perplexity on single lstm\n",
    "test_perplexity(single_lstm_model, ctx, test_indices, idx_to_char, char_to_idx, num_epochs, num_steps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, perplexity 4.599602, time 3.33 sec\n",
      "epoch 2, perplexity 4.598010, time 3.42 sec\n",
      "epoch 3, perplexity 4.597947, time 3.44 sec\n",
      "epoch 4, perplexity 4.597218, time 3.42 sec\n",
      "epoch 5, perplexity 4.597271, time 3.39 sec\n"
     ]
    }
   ],
   "source": [
    "# test perplexity on gru\n",
    "test_perplexity(single_gru_model, ctx, test_indices, idx_to_char, char_to_idx, num_epochs, num_steps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, perplexity 5.077668, time 7.28 sec\n",
      "epoch 2, perplexity 5.082510, time 4.92 sec\n",
      "epoch 3, perplexity 5.080637, time 4.86 sec\n",
      "epoch 4, perplexity 5.082147, time 5.42 sec\n",
      "epoch 5, perplexity 5.079242, time 5.48 sec\n"
     ]
    }
   ],
   "source": [
    "# test perplexity on double lstm\n",
    "test_perplexity(double_lstm_model, ctx, test_indices, idx_to_char, char_to_idx, num_epochs, num_steps, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. $N$-Gram Model\n",
    "\n",
    "So far we only considered latent variable models. Let's see what happens if we use a regular $N$-gram model and an autoregressive setting. That is, we aim to predict the next character given the current characters one character at a time. For this implement the following:\n",
    "\n",
    "1. Split data into $(x,y)$ pairs as before, just that we now use very short subsequences, e.g. only $5$ characters. That is, `But Brutus` turns into the tuples (`(But B, r)`, `(ut Br, u)`, `(t Bru, t)`, `( Brut, u)`, `(Brutu, s)`). \n",
    "1. Use one-hot encoding for each character separately and combine them all. \n",
    "    * In one case use a sequential encoding to obtain an embedding proportional to the length of the sequence.\n",
    "    * Use a bag of characters encoding that sums over all occurrences.\n",
    "1. Implement an MLP with one hidden layer and 256 hidden units.\n",
    "1. Train it to output the next character.\n",
    "\n",
    "How accurate is the model? How does the number of operations and weights compare to an RNN, a GRU and an LSTM discussed above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
