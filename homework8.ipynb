{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Homework 8 - Berkeley STAT 157\n",
    "\n",
    "**Your name: XX, SID YY, teammates A,B,C** (Please add your name, SID and teammates to ease Ryan and Rachel to grade.)\n",
    "\n",
    "**Please submit your homework through [gradescope](http://gradescope.com/)**\n",
    "\n",
    "Handout 4/9/2019, due 4/16/2019 by 4pm.\n",
    "\n",
    "This homework deals with sequence models for text and numbers. Due to the computational cost, we strongly encourage you to implement this on a GPU enabled machine. To make things a bit more interesting we will use a larger text collection here - [Shakespeare's collected works](http://www.gutenberg.org/files/100/100-0.txt) which are freely downloadable at Project Gutenberg. \n",
    "\n",
    "**This is teamwork.**\n",
    "\n",
    "## Prerequisites - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters:  5032359\n",
      "project gutenberg s the complete works of william shakespeare by willi\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import collections\n",
    "import re\n",
    "shakespeare = 'http://www.gutenberg.org/files/100/100-0.txt'\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "text = http.request('GET', shakespeare).data.decode('utf-8')\n",
    "raw_dataset = ' '.join(re.sub('[^A-Za-z]+', ' ', text).lower().split())\n",
    "\n",
    "print('number of characters: ', len(raw_dataset))\n",
    "print(raw_dataset[0:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is quite a bit bigger than the time machine (5 million vs. 160k). For convenience we also include the remaining preprocessing steps. A bigger dataset will allow us to generate more meaningful models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars: project gutenberg s \n",
      "indices: [23, 11, 20, 24, 22, 4, 25, 5, 0, 6, 25, 22, 7, 15, 22, 11, 0, 5, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "idx_to_char = list(set(raw_dataset))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "vocab_size = len(char_to_idx)\n",
    "corpus_indices = [char_to_idx[char] for char in raw_dataset]\n",
    "sample = corpus_indices[:20]\n",
    "print('chars:', ''.join([idx_to_char[idx] for idx in sample]))\n",
    "print('indices:', sample)\n",
    "train_indices = corpus_indices[:-100000]\n",
    "test_indices = corpus_indices[-100000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we import other useful libraries to help you getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "import math\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn, rnn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train Recurrent Latent Variable Models\n",
    "\n",
    "Train a number of different latent variable models using `train_indices` to assess their performance. By default pick 256 dimensions for the hidden units. You can use the codes provided in the class. Also, we strongly encourage you to use the Gluon implementation since it's a lot faster than building it from scratch.\n",
    "\n",
    "1. Train a single-layer RNN (with latent variables). \n",
    "1. Train a single-layer GRU.\n",
    "1. Train a single-layer LSTM. \n",
    "1. Train a two-layer LSTM. \n",
    "\n",
    "How low can you drive the perplexity? Can you reproduce some of Shakespeare's finest writing (generate 200 characters). Start the sequence generator with `But Brutus is an honorable man`. Experiment with a number of settings:\n",
    "\n",
    "* Number of hidden units. \n",
    "* Embedding length.\n",
    "* Gradient clipping.\n",
    "* Number of iterations. \n",
    "* Learning rate.\n",
    "\n",
    "**Save** the models (at least in memory since you'll need them in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[11:16:27] /home/builder/nwani/m3/conda-bld/libmxnet_1533369713073/work/3rdparty/dmlc-core/include/dmlc/./any.h:286: Check failed: type_ != nullptr The any container is empty requested=N5mxnet10Imperative6AGInfoE\n\nStack trace returned 10 entries:\n[bt] (0) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x189) [0x7fb26386ffa9]\n[bt] (1) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x3b) [0x7fb263870a5b]\n[bt] (2) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(void dmlc::any::check_type<mxnet::Imperative::AGInfo>() const+0x1e0) [0x7fb265ff6b50]\n[bt] (3) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::Backward(std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool, bool, bool)+0x1e8c) [0x7fb265fede1c]\n[bt] (4) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(MXAutogradBackwardEx+0x90d) [0x7fb2664f500d]\n[bt] (5) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fb297578ec0]\n[bt] (6) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fb29757887d]\n[bt] (7) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb29778eede]\n[bt] (8) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x13915) [0x7fb29778f915]\n[bt] (9) /home/steven/anaconda3/envs/stat/bin/python(_PyObject_FastCallDict+0x8b) [0x55dd45a8892b]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0d42c6bd603b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m d2l.train_and_predict_rnn_gluon(model, num_hiddens, vocab_size, ctx, corpus_indices, idx_to_char,\\\n\u001b[1;32m     15\u001b[0m                                 \u001b[0mchar_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipping_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                 pred_period, pred_len, prefixes)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/stat/lib/python3.6/site-packages/d2l/utils.py\u001b[0m in \u001b[0;36mtrain_and_predict_rnn_gluon\u001b[0;34m(model, num_hiddens, vocab_size, ctx, corpus_indices, idx_to_char, char_to_idx, num_epochs, num_steps, lr, clipping_theta, batch_size, pred_period, pred_len, prefixes)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mgrad_clipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipping_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [11:16:27] /home/builder/nwani/m3/conda-bld/libmxnet_1533369713073/work/3rdparty/dmlc-core/include/dmlc/./any.h:286: Check failed: type_ != nullptr The any container is empty requested=N5mxnet10Imperative6AGInfoE\n\nStack trace returned 10 entries:\n[bt] (0) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x189) [0x7fb26386ffa9]\n[bt] (1) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x3b) [0x7fb263870a5b]\n[bt] (2) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(void dmlc::any::check_type<mxnet::Imperative::AGInfo>() const+0x1e0) [0x7fb265ff6b50]\n[bt] (3) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::Backward(std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool, bool, bool)+0x1e8c) [0x7fb265fede1c]\n[bt] (4) /home/steven/anaconda3/envs/stat/lib/python3.6/site-packages/mxnet/libmxnet.so(MXAutogradBackwardEx+0x90d) [0x7fb2664f500d]\n[bt] (5) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fb297578ec0]\n[bt] (6) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fb29757887d]\n[bt] (7) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb29778eede]\n[bt] (8) /home/steven/anaconda3/envs/stat/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x13915) [0x7fb29778f915]\n[bt] (9) /home/steven/anaconda3/envs/stat/bin/python(_PyObject_FastCallDict+0x8b) [0x55dd45a8892b]\n\n"
     ]
    }
   ],
   "source": [
    "# for question 1.1: train a single-layer RNN\n",
    "num_hiddens = 256\n",
    "rnn_layer = rnn.RNN(num_hiddens)\n",
    "rnn_layer.initialize()\n",
    "batch_size = 2\n",
    "state = rnn_layer.begin_state(batch_size = batch_size)\n",
    "num_steps = 35\n",
    "\n",
    "ctx = d2l.try_gpu()\n",
    "model = d2l.RNNModel(rnn_layer, vocab_size)\n",
    "model.initialize(force_reinit=True, ctx = ctx)\n",
    "num_epochs, batch_size, lr, clipping_theta = 200, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, 'but brutus is an honorable man'\n",
    "d2l.train_and_predict_rnn_gluon(model, num_hiddens, vocab_size, ctx, corpus_indices, idx_to_char,\\\n",
    "                                char_to_idx, num_epochs, num_steps, lr, clipping_theta, batch_size,\\\n",
    "                                pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_gluon(prefix, num_chars, model, vocab_size, ctx, idx_to_char, char_to_idx):\n",
    "    state = model.begin_state(batch_size=1, ctx=ctx)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = nd.array([output[-1]], ctx=ctx).reshape((1, 1))\n",
    "        (Y, state) = model(X, state)\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(axis=1).asscalar()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "collapsed": true
   },
   "source": [
    "## 2. Test Error\n",
    "\n",
    "So far we measured perplexity only on the training set. \n",
    "\n",
    "1. Implement a perplexity calculator that does not involve training.\n",
    "1. Compute the perplexity of the best models in each of the 4 categories on the test set. By how much does it differ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. $N$-Gram Model\n",
    "\n",
    "So far we only considered latent variable models. Let's see what happens if we use a regular $N$-gram model and an autoregressive setting. That is, we aim to predict the next character given the current characters one character at a time. For this implement the following:\n",
    "\n",
    "1. Split data into $(x,y)$ pairs as before, just that we now use very short subsequences, e.g. only $5$ characters. That is, `But Brutus` turns into the tuples (`(But B, r)`, `(ut Br, u)`, `(t Bru, t)`, `( Brut, u)`, `(Brutu, s)`). \n",
    "1. Use one-hot encoding for each character separately and combine them all. \n",
    "    * In one case use a sequential encoding to obtain an embedding proportional to the length of the sequence.\n",
    "    * Use a bag of characters encoding that sums over all occurrences.\n",
    "1. Implement an MLP with one hidden layer and 256 hidden units.\n",
    "1. Train it to output the next character.\n",
    "\n",
    "How accurate is the model? How does the number of operations and weights compare to an RNN, a GRU and an LSTM discussed above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
