{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Berkeley STAT 157\n",
    "\n",
    "Handout 1/29/2019, due 2/5/2019 by 4pm in Git by committing to your repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.163323Z",
     "start_time": "2019-01-29T22:48:53.680455Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd, autograd, gluon\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:41:18.204791Z",
     "start_time": "2019-01-29T19:41:18.201091Z"
    }
   },
   "source": [
    "# 1. Multinomial Sampling\n",
    "\n",
    "Implement a sampler from a discrete distribution from scratch, mimicking the function `mxnet.ndarray.random.multinomial`. Its arguments should be a vector of probabilities $p$. You can assume that the probabilities are normalized, i.e. tha they sum up to $1$. Make the call signature as follows:\n",
    "\n",
    "```\n",
    "samples = sampler(probs, shape) \n",
    "\n",
    "probs   : An ndarray vector of size n of nonnegative numbers summing up to 1\n",
    "shape   : A list of dimensions for the output\n",
    "samples : Samples from probs with shape matching shape\n",
    "```\n",
    "\n",
    "Hints:\n",
    "\n",
    "1. Use `mxnet.ndarray.random.uniform` to get a sample from $U[0,1]$.\n",
    "1. You can simplify things for `probs` by computing the cumulative sum over `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.185124Z",
     "start_time": "2019-01-29T22:48:56.165645Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.95279163 0.45612976 0.68748826]\n",
      " [0.48340863 0.21550767 0.78873944]]\n",
      "<NDArray 2x3 @cpu(0)>\n",
      "\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[0. 1. 0.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[1. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[0. 0. 0.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[1. 1. 0.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[0. 0. 1.]\n",
      "<NDArray 3 @cpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.         0.33333334 0.6666667 ]\n",
       " [0.         0.6666667  0.33333334]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sampler(probs, shape):\n",
    "    ## Add your codes here\n",
    "    ret=nd.zeros(shape=shape)\n",
    "    m, n=shape\n",
    "    num=1000000\n",
    "    y=nd.random.uniform(shape=shape)\n",
    "    print(y)\n",
    "    x=nd.zeros(shape=n)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            x1=y[i]<probs[:j+1].sum() \n",
    "            x2=y[i]>probs[:j].sum()\n",
    "            for k in range(n):\n",
    "                if x1[k]==1 and x2[k]==1:\n",
    "                    x[k]=1\n",
    "                else:\n",
    "                    x[k]=0\n",
    "            print(x)\n",
    "            ret[i, j]+=x.sum()\n",
    "    ret/=n\n",
    "    return ret\n",
    "\n",
    "# a simple test\n",
    "sampler(nd.array([0.2, 0.3, 0.5]), (2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Central Limit Theorem\n",
    "\n",
    "Let's explore the Central Limit Theorem when applied to text processing. \n",
    "\n",
    "* Download [https://www.gutenberg.org/ebooks/84](https://www.gutenberg.org/files/84/84-0.txt) from Project Gutenberg \n",
    "* Remove punctuation, uppercase / lowercase, and split the text up into individual tokens (words).\n",
    "* For the words `a`, `and`, `the`, `i`, `is` compute their respective counts as the book progresses, i.e. \n",
    "    $$n_\\mathrm{the}[i] = \\sum_{j = 1}^i \\{w_j = \\mathrm{the}\\}$$\n",
    "* Plot the proportions $n_\\mathrm{word}[i] / i$ over the document in one plot.\n",
    "* Find an envelope of the shape $O(1/\\sqrt{i})$ for each of these five words.\n",
    "* Why can we **not** apply the Central Limit Theorem directly? \n",
    "* How would we have to change the text for it to apply? \n",
    "* Why does it still work quite well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.200892Z",
     "start_time": "2019-01-29T22:48:56.188145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿\n",
      "Project Gutenberg's Frankenstein, by Mary Wollstonecraft (Godwin) Shelley\n",
      "\n",
      "This eBook is for the use\n"
     ]
    }
   ],
   "source": [
    "filename = gluon.utils.download('https://www.gutenberg.org/files/84/84-0.txt')\n",
    "with open(filename, encoding='utf-8') as f:\n",
    "    book = f.read()\n",
    "print(book[0:100])\n",
    "\n",
    "## Add your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Denominator-layout notation\n",
    "\n",
    "We used the numerator-layout notation for matrix calculus in class, now let's examine the denominator-layout notation.\n",
    "\n",
    "Given $x, y\\in\\mathbb R$, $\\mathbf x\\in\\mathbb R^n$ and $\\mathbf y \\in \\mathbb R^m$, we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial \\mathbf{x}}=\\begin{bmatrix}\n",
    "\\frac{\\partial y}{\\partial x_1}\\\\\n",
    "\\frac{\\partial y}{\\partial x_2}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial y}{\\partial x_n}\n",
    "\\end{bmatrix},\\quad \n",
    "\\frac{\\partial \\mathbf y}{\\partial {x}}=\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x}, \n",
    "\\frac{\\partial y_2}{\\partial x}, \n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf y}{\\partial \\mathbf{x}}\n",
    "=\\begin{bmatrix}\n",
    "\\frac{\\partial \\mathbf y}{\\partial {x_1}}\\\\\n",
    "\\frac{\\partial \\mathbf y}{\\partial {x_2}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial \\mathbf y}{\\partial {x_3}}\\\\\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1}, \n",
    "\\frac{\\partial y_2}{\\partial x_1},\n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x_1}\n",
    "\\\\ \n",
    "\\frac{\\partial y_1}{\\partial x_2},\n",
    "\\frac{\\partial y_2}{\\partial x_2},\n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x_2}\\\\ \n",
    "\\vdots\\\\\n",
    "\\frac{\\partial y_1}{\\partial x_n},\n",
    "\\frac{\\partial y_2}{\\partial x_n},\n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Questions: \n",
    "\n",
    "1. Assume $\\mathbf  y = f(\\mathbf u)$ and $\\mathbf u = g(\\mathbf x)$, write down the chain rule for $\\frac {\\partial\\mathbf  y}{\\partial\\mathbf x}$\n",
    "2. Given $\\mathbf X \\in \\mathbb R^{m\\times n},\\ \\mathbf w \\in \\mathbb R^n, \\ \\mathbf y \\in \\mathbb R^m$, assume $z = \\| \\mathbf X \\mathbf w - \\mathbf y\\|^2$, compute $\\frac{\\partial z}{\\partial\\mathbf w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:\n",
    "\n",
    "1. $\\frac{\\partial \\mathbf y}{\\partial \\mathbf x}=\\frac{\\partial \\mathbf y}{\\partial \\mathbf u}\\frac{\\partial \\mathbf u}{\\partial \\mathbf x}$\n",
    "2. Suppose $\\mathbf u=\\mathbf X\\mathbf w-\\mathbf y$, $\\mathbf v=\\mathbf X\\mathbf w$, then\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial \\mathbf w}=\\frac{\\partial z}{\\partial \\mathbf u}\\frac{\\partial \\mathbf u}{\\partial \\mathbf v}\\frac{\\partial \\mathbf v}{\\partial \\mathbf w}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "z=\\Vert \\mathbf u\\Vert^2, \\mathbf u=\\mathbf v-\\mathbf y, \\mathbf v=\\mathbf X\\mathbf w\\\\\n",
    "\\frac{\\partial z}{\\partial \\mathbf u}=2\\mathbf u^\\top\\\\\n",
    "\\frac{\\partial \\mathbf u}{\\partial \\mathbf v}=\\mathbf I-\\frac{\\partial \\mathbf y}{\\partial \\mathbf v}=\\mathbf I\\\\\n",
    "\\frac{\\partial \\mathbf v}{\\partial \\mathbf w}=\\mathbf X\n",
    "$$\n",
    "Therefore\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial \\mathbf w}=2(\\mathbf X\\mathbf w-\\mathbf y)^\\top\\mathbf X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Numerical Precision\n",
    "\n",
    "Given scalars `x` and `y`, implement the following `log_exp` function such that it returns a numerically stable version of \n",
    "$$-\\log\\left(\\frac{e^x}{e^x+e^y}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.206890Z",
     "start_time": "2019-01-29T22:48:56.202996Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_exp(x, y):\n",
    "    ## add your solution here\n",
    "    return -nd.log(1/(1+nd.exp(y-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your codes with normal inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.215579Z",
     "start_time": "2019-01-29T22:48:56.209659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.3132616]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = nd.array([2]), nd.array([3])\n",
    "z = log_exp(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement a function to compute $\\partial z/\\partial x$ and $\\partial z/\\partial y$ with `autograd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.223303Z",
     "start_time": "2019-01-29T22:48:56.218056Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad(forward_func, x, y): \n",
    "    x.attach_grad()\n",
    "    y.attach_grad()\n",
    "    with autograd.record():\n",
    "        z=forward_func(x, y)\n",
    "    z.backward()\n",
    "    print('x.grad =', x.grad)\n",
    "    print('y.grad =', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your codes, it should print the results nicely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.267165Z",
     "start_time": "2019-01-29T22:48:56.227035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = \n",
      "[-0.7310586]\n",
      "<NDArray 1 @cpu(0)>\n",
      "y.grad = \n",
      "[0.7310586]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "grad(log_exp, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now let's try some \"hard\" inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.285842Z",
     "start_time": "2019-01-29T22:48:56.274079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = \n",
      "[-0.]\n",
      "<NDArray 1 @cpu(0)>\n",
      "y.grad = \n",
      "[0.]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x, y = nd.array([50]), nd.array([100])\n",
    "grad(log_exp, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does your code return correct results? If not, try to understand the reason. (Hint, evaluate `exp(100)`). Now develop a new function `stable_log_exp` that is identical to `log_exp` in math, but returns a more numerical stable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.305595Z",
     "start_time": "2019-01-29T22:48:56.293399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = \n",
      "[-1.]\n",
      "<NDArray 1 @cpu(0)>\n",
      "y.grad = \n",
      "[1.]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "def stable_log_exp(x, y):\n",
    "    ## Add your codes here\n",
    "    if x>y:\n",
    "        return -nd.log(1/(1+nd.exp(y-x)))\n",
    "    else:\n",
    "        return -nd.log(nd.exp(x-y)/(1+nd.exp(x-y)))\n",
    "grad(stable_log_exp, x, y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
