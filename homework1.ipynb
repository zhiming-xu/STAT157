{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 1 - Berkeley STAT 157\n",
    "\n",
    "Handout 1/22/2017, due 1/29/2017 by 4pm in Git by committing to your repository. Please ensure that you add the TA Git account to your repository.\n",
    "\n",
    "1. Write all code in the notebook.\n",
    "1. Write all text in the notebook. You can use MathJax to insert math or generic Markdown to insert figures (it's unlikely you'll need the latter). \n",
    "1. **Execute** the notebook and **save** the results.\n",
    "1. To be safe, print the notebook as PDF and add it to the repository, too. Your repository should contain two files: ``homework1.ipynb`` and ``homework1.pdf``. \n",
    "\n",
    "The TA will return the corrected and annotated homework back to you via Git (please give `rythei` access to your repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T19:57:47.188990Z",
     "start_time": "2019-01-22T19:57:46.107420Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import ndarray as nd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Speedtest for vectorization\n",
    "\n",
    "Your goal is to measure the speed of linear algebra operations for different levels of vectorization. You need to use `wait_to_read()` on the output to ensure that the result is computed completely, since NDArray uses asynchronous computation. Please see http://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.NDArray.wait_to_read.html for details. \n",
    "\n",
    "1. Construct two matrices $A$ and $B$ with Gaussian random entries of size $4096 \\times 4096$. \n",
    "1. Compute $C = A B$ using matrix-matrix operations and report the time. \n",
    "1. Compute $C = A B$, treating $A$ as a matrix but computing the result for each column of $B$ one at a time. Report the time.\n",
    "1. Compute $C = A B$, treating $A$ and $B$ as collections of vectors. Report the time.\n",
    "1. Bonus question - what changes if you execute this on a GPU?\n",
    "    - It will be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct dot-product time is:  3.5399234294891357 s\n",
      "Treat B as column vectors, time is:  15.46968412399292 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d2099f73e319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_to_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Treat A, B as collection of vectors, time is '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\stat\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mindexing_dispatch_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_indexing_dispatch_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexing_dispatch_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_NDARRAY_BASIC_INDEXING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_nd_basic_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mindexing_dispatch_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_NDARRAY_ADVANCED_INDEXING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_nd_advanced_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\stat\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36m_set_nd_basic_indexing\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0moshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[0mvalue_nd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_nd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[0m_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_assign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_nd_advanced_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\stat\\lib\\site-packages\\mxnet\\ndarray\\register.py\u001b[0m in \u001b[0;36m_slice_assign\u001b[1;34m(lhs, rhs, begin, end, step, out, name, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\stat\\lib\\site-packages\\mxnet\\_ctypes\\ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[1;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CPU, the time is ~5s, ~20s, ~5000s separately\n",
    "A=nd.random.normal(shape=[4096,4096])\n",
    "B=nd.random.normal(shape=[4096,4096])\n",
    "t1=time.time()\n",
    "C=nd.dot(A,B)\n",
    "C.wait_to_read()\n",
    "print('Direct dot-product time is: ', time.time()-t1, 's')\n",
    "\n",
    "t2=time.time()\n",
    "for i in range(4096):\n",
    "    C[:,1]=nd.dot(A,B[:,i])\n",
    "C.wait_to_read()\n",
    "print('Treat B as column vectors, time is: ', time.time()-t2, 's')\n",
    "\n",
    "t3=time.time()\n",
    "for i in range(4096):\n",
    "    for j in range(4096):\n",
    "        C[i,j]=nd.dot(A[i,:],B[:,j])\n",
    "C.wait_to_read()\n",
    "print('Treat A, B as collection of vectors, time is ', time.time()-t3, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] Direct dot-product time is:  0.266162633895874 s\n",
      "[GPU] Treat B as column vectors, time is:  9.777193069458008 s\n"
     ]
    }
   ],
   "source": [
    "# GPU, the time is ~.5s, ~10s,  \n",
    "with mx.Context(mx.gpu()):\n",
    "    A=nd.random.normal(shape=[4096,4096])\n",
    "    B=nd.random.normal(shape=[4096,4096])\n",
    "    A\n",
    "    B\n",
    "    t1=time.time()\n",
    "    C=nd.dot(A,B)\n",
    "    C.wait_to_read()\n",
    "    print('[GPU] Direct dot-product time is: ', time.time()-t1, 's')\n",
    "\n",
    "    t2=time.time()\n",
    "    for i in range(4096):\n",
    "        C[:,1]=nd.dot(A,B[:,i])\n",
    "    C.wait_to_read()\n",
    "    print('[GPU] Treat B as column vectors, time is: ', time.time()-t2, 's')\n",
    "\n",
    "    t3=time.time()\n",
    "    for i in range(4096):\n",
    "        for j in range(4096):\n",
    "            C[i,j]=nd.dot(A[i,:],B[:,j])\n",
    "    C.wait_to_read()\n",
    "    print('[GPU] Treat A, B as collection of vectors, time is ', time.time()-t3, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Semidefinite Matrices\n",
    "\n",
    "Assume that $A \\in \\mathbb{R}^{m \\times n}$ is an arbitrary matrix and that $D \\in \\mathbb{R}^{n \\times n}$ is a diagonal matrix with nonnegative entries. \n",
    "\n",
    "1. Prove that $B = A D A^\\top$ is a positive semidefinite matrix. \n",
    "1. When would it be useful to work with $B$ and when is it better to use $A$ and $D$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can prove B to be positive semidefinite by showing that there exists some matrix $Q$, s.t. $B=Q^\\top Q$. Since $B=ADA^\\top$ and $D$ is a diagonal matrix with nonnegative entries, we can set $Q=\\sqrt{D}A^\\top$, thus $Q^\\top=A\\sqrt{D}$. Hence $Q^\\top Q=A\\sqrt{D}\\sqrt{D}A\\top=ADA^\\top=B$. By definition, we have proved  that $B$ is positive semidefinite.\n",
    "2. When it comes to multiply B with another matrix or vector, it is better to use $B$. But if we want to calculate $B$ to its power (like $B\\cdot B\\cdot B\\cdots$), then we can do faster with $A$ and $D$ if $m$ is much larger than $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MXNet on GPUs\n",
    "\n",
    "1. Install GPU drivers (if needed)\n",
    "1. Install MXNet on a GPU instance\n",
    "1. Display `!nvidia-smi`\n",
    "1. Create a $2 \\times 2$ matrix on the GPU and print it. See http://d2l.ai/chapter_deep-learning-computation/use-gpu.html for details.\n",
    "\n",
    "### Note\n",
    "I managed to install cuda on my Surfacebook and run the code below on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 28 22:09:32 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 417.71       Driver Version: 417.71       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GPU        WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   37C    P8     1W /  N/A |     36MiB /  1024MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1.]\n",
       " [1. 1.]]\n",
       "<NDArray 2x2 @gpu(0)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import ndarray as nd\n",
    "!nvidia-smi\n",
    "x = nd.ones((2, 2), ctx=mx.gpu())\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NDArray and NumPy \n",
    "\n",
    "Your goal is to measure the speed penalty between MXNet Gluon and Python when converting data between both. We are going to do this as follows:\n",
    "\n",
    "1. Create two Gaussian random matrices $A, B$ of size $4096 \\times 4096$ in NDArray. \n",
    "1. Compute a vector $\\mathbf{c} \\in \\mathbb{R}^{4096}$ where $c_i = \\|A B_{i\\cdot}\\|^2$ where $\\mathbf{c}$ is a **NumPy** vector.\n",
    "\n",
    "To see the difference in speed due to Python perform the following two experiments and measure the time:\n",
    "\n",
    "1. Compute $\\|A B_{i\\cdot}\\|^2$ one at a time and assign its outcome to $\\mathbf{c}_i$ directly.\n",
    "1. Use an intermediate storage vector $\\mathbf{d}$ in NDArray for assignments and copy to NumPy at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign outcome to c_i directly:  16.207096815109253\n",
      "Assign to intermediate storage d:  12.968188047409058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "c=np.ndarray([4096,1])\n",
    "A=nd.random.normal(shape=[4096,4096])\n",
    "B=nd.random.normal(shape=[4096,4096])\n",
    "t1=time.time()\n",
    "for i in range(4096):\n",
    "    c[i]=nd.norm(nd.dot(A, B[:, i])).asnumpy()\n",
    "print('Assign outcome to c_i directly: ', time.time()-t1)\n",
    "\n",
    "d=nd.zeros(shape=[4096,1])\n",
    "t2=time.time()\n",
    "for i in range(4096):\n",
    "    d[i]=nd.norm(nd.dot(A, B[:, i]))\n",
    "c=d.asnumpy()\n",
    "print('Assign to intermediate storage d: ', time.time()-t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Memory efficient computation\n",
    "\n",
    "We want to compute $C \\leftarrow A \\cdot B + C$, where $A, B$ and $C$ are all matrices. Implement this in the most memory efficient manner. Pay attention to the following two things:\n",
    "\n",
    "1. Do not allocate new memory for the new value of $C$.\n",
    "1. Do not allocate new memory for intermediate results if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialize some matrices A, B and C\n",
    "A=nd.random.normal(shape=[4096,4096])\n",
    "B=nd.random.normal(shape=[4096,4096])\n",
    "C=nd.random.normal(shape=[4096,4096])\n",
    "# print(nd.dot(A, B)-nd.elemwise_mul(A, B))\n",
    "# print(id(C))\n",
    "C[:]+=nd.dot(A, B)\n",
    "# print(id(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Broadcast Operations\n",
    "\n",
    "In order to perform polynomial fitting we want to compute a design matrix $A$ with \n",
    "\n",
    "$$A_{ij} = x_i^j$$\n",
    "\n",
    "Our goal is to implement this **without a single for loop** entirely using vectorization and broadcast. Here $1 \\leq j \\leq 20$ and $x = \\{-10, -9.9, \\ldots 10\\}$. Implement code that generates such a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-1.0000000e+01  1.0000000e+02 -1.0000000e+03  1.0000000e+04]\n",
       " [-1.0000000e+05  1.0000000e+06 -1.0000000e+07  1.0000000e+08]\n",
       " [-1.0000000e+09  1.0000000e+10 -9.9999998e+10  1.0000000e+12]\n",
       " [-9.9999998e+12  1.0000000e+14 -9.9999999e+14  1.0000000e+16]\n",
       " [-9.9999998e+16  9.9999998e+17 -1.0000000e+19  1.0000000e+20]\n",
       " [-9.8999996e+00  9.8009995e+01 -9.7029889e+02  9.6059590e+03]\n",
       " [-9.5098984e+04  9.4147994e+05 -9.3206510e+06  9.2274440e+07]\n",
       " [-9.1351693e+08  9.0438175e+09 -8.9533784e+10  8.8638449e+11]\n",
       " [-8.7752059e+12  8.6874538e+13 -8.6005787e+14  8.5145724e+15]\n",
       " [-8.4294265e+16  8.3451318e+17 -8.2616803e+18  8.1790629e+19]\n",
       " [-9.8000002e+00  9.6040001e+01 -9.4119208e+02  9.2236826e+03]\n",
       " [-9.0392086e+04  8.8584250e+05 -8.6812570e+06  8.5076312e+07]\n",
       " [-8.3374790e+08  8.1707295e+09 -8.0073155e+10  7.8471692e+11]\n",
       " [-7.6902260e+12  7.5364211e+13 -7.3856929e+14  7.2379793e+15]\n",
       " [-7.0932201e+16  6.9513558e+17 -6.8123289e+18  6.6760824e+19]\n",
       " [-9.6999998e+00  9.4089996e+01 -9.1267297e+02  8.8529277e+03]\n",
       " [-8.5873391e+04  8.3297194e+05 -8.0798275e+06  7.8374320e+07]\n",
       " [-7.6023091e+08  7.3742397e+09 -7.1530127e+10  6.9384221e+11]\n",
       " [-6.7302693e+12  6.5283608e+13 -6.3325098e+14  6.1425345e+15]\n",
       " [-5.9582582e+16  5.7795107e+17 -5.6061250e+18  5.4379413e+19]\n",
       " [-9.6000004e+00  9.2160004e+01 -8.8473608e+02  8.4934668e+03]]\n",
       "<NDArray 21x4 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose we implement the calculation as a function\n",
    "# The input parameters are vector x and power j, and the return value is the design matrix A\n",
    "def design_mat(j):\n",
    "    e=nd.arange(1, 21).reshape(1, 20)\n",
    "    x=nd.arange(-10.0, 10.1, step=0.1).reshape(201, 1)\n",
    "    A=x**e\n",
    "    return A.reshape(21, j)\n",
    "design_mat(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
